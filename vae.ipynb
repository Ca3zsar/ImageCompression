{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 00:29:26.815000: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-15 00:29:27.041842: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-15 00:29:28.276554: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BINARY_SIZE = 1\n",
    "PATCH_SIZE = 8\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_name):\n",
    "    import keras.datasets as datasets\n",
    "    (x_train, _), (x_test, _) = getattr(datasets, dataset_name).load_data()\n",
    "\n",
    "    x_train = np.append(x_train, x_test, axis=0)\n",
    "    x_train = x_train.astype('float32') / 255.\n",
    "    return x_train\n",
    "\n",
    "def get_data():\n",
    "    cifar10_dataset = load_dataset('cifar10')\n",
    "    cifar100_dataset = load_dataset('cifar100')\n",
    "    # stl10_dataset = load_dataset('stl10')\n",
    "\n",
    "    # append the datasets\n",
    "    dataset = np.append(cifar10_dataset, cifar100_dataset, axis=0)\n",
    "    # dataset = np.append(dataset,  axis=0)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def get_simple_data():\n",
    "    cifar10_dataset = load_dataset('cifar10')\n",
    "\n",
    "    return cifar10_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_simple_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 00:29:31.973062: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:29:32.097383: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:29:32.097505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:29:32.102627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:29:32.102694: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:29:32.102710: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:29:32.315942: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:29:32.316097: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:29:32.316115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-15 00:29:32.316176: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:29:32.316299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1753 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.image.extract_patches(dataset, sizes=[1, PATCH_SIZE, PATCH_SIZE, 1], strides=[1, PATCH_SIZE, PATCH_SIZE, 1], rates=[1, 1, 1, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.reshape(dataset, [-1, PATCH_SIZE, PATCH_SIZE, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 00:29:34.331788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "# dataset to ycbcr\n",
    "dataset = tf.image.rgb_to_yuv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[:int(len(dataset) * 0.8)]\n",
    "test_dataset = dataset[int(len(dataset) * 0.8):]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_dataset).shuffle(int(len(train_dataset) * 0.8)).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_dataset).shuffle(int(len(test_dataset) * 0.8)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "  \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "  def __init__(self, latent_dim):\n",
    "    super(CVAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(8, 8, 3)),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            # No activation\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=2*2*32, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(2, 2, 32)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=3, kernel_size=3, strides=1, padding='same'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  @tf.function\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "    return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "  def encode(self, x):\n",
    "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "\n",
    "  def reparameterize(self, mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "  def decode(self, z, apply_sigmoid=False):\n",
    "    logits = self.decoder(z)\n",
    "    if apply_sigmoid:\n",
    "      probs = tf.sigmoid(logits)\n",
    "      return probs\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "  mean, logvar = model.encode(x)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  x_logit = model.decode(z)\n",
    "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "  logpz = log_normal_pdf(z, 0., 0.)\n",
    "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "  \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "  This function computes the loss and gradients, and uses the latter to\n",
    "  update the model's parameters.\n",
    "  \"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = compute_loss(model, x)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 2\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim])\n",
    "model = CVAE(latent_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_sample):\n",
    "  mean, logvar = model.encode(test_sample)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  predictions = model.sample(z)\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "  # tight_layout minimizes the overlap between 2 sub-plots\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 00:29:34.801994: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [192000,8,8,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-04-15 00:29:34.802230: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [192000,8,8,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "assert BATCH_SIZE >= num_examples_to_generate\n",
    "test_batch = next(iter(test_dataset.take(1)))\n",
    "test_sample = test_batch[0:num_examples_to_generate, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 8, 8, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Test set ELBO: 5006595058565120.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_and_save_images(model, 0, test_sample)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "  for train_x in train_dataset:\n",
    "    train_step(model, train_x, optimizer)\n",
    "\n",
    "  loss = tf.keras.metrics.Mean()\n",
    "  for test_x in test_dataset:\n",
    "    loss(compute_loss(model, test_x))\n",
    "  elbo = -loss.result()\n",
    "  display.clear_output(wait=False)\n",
    "  print('Epoch: {}, Test set ELBO: {}'\n",
    "        .format(epoch, elbo))\n",
    "  generate_and_save_images(model, epoch, test_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(image: np.ndarray, patch_size: int):\n",
    "    h, w, c = image.shape\n",
    "    h_pad = (patch_size - (h % patch_size)) % patch_size\n",
    "    w_pad = (patch_size - (w % patch_size)) % patch_size\n",
    "\n",
    "    return np.pad(image, ((0, h_pad), (0, w_pad), (0, 0)), mode='constant', constant_values=0), h_pad, w_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_image(image: np.ndarray, network: tf.keras.Model) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compress an image using the given network\n",
    "    :param image: The image to compress\n",
    "    :param network: The network to use for compression\n",
    "    :return: The compressed image & the bits\n",
    "    \"\"\"\n",
    "    patch_size = PATCH_SIZE\n",
    "\n",
    "    # pad the image\n",
    "    image, h_pad, w_pad = pad_image(image, patch_size)\n",
    "    \n",
    "    height, width, channels = image.shape\n",
    "    no_patches_width = width // patch_size\n",
    "    no_patches_height = height // patch_size\n",
    "    \n",
    "    # transform image to list with a single element\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "    image = tf.image.extract_patches(image, sizes=[1, patch_size, patch_size, 1], strides=[1, patch_size, patch_size, 1], rates=[1, 1, 1, 1], padding='VALID')\n",
    "    image = tf.reshape(image, [-1, patch_size,patch_size,3])\n",
    "\n",
    "    reconstructed_patches = []\n",
    "    for i in range(len(image)):\n",
    "        x = image[i]\n",
    "        mean, logvar = model.encode(x)\n",
    "        z = model.reparameterize(mean, logvar)\n",
    "        x_logit = model.decode(z)\n",
    "        reconstructed_patches.append(x_logit)\n",
    "    reconstructed_image = np.zeros((height, width, channels))\n",
    "\n",
    "    for i in range(no_patches_height):\n",
    "        for j in range(no_patches_width):\n",
    "            patch = reconstructed_patches[i*no_patches_width+j].reshape(patch_size, patch_size, 3)\n",
    "            # print(i*patch_size, (i+1)*patch_size, j*patch_size, (j+1)*patch_size)\n",
    "            reconstructed_image[i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size] = patch\n",
    "\n",
    "    height = height - h_pad\n",
    "    width = width - w_pad\n",
    "\n",
    "    reconstructed_image = reconstructed_image[:height, :width]\n",
    "\n",
    "    # convert reconstructed image to tensor\n",
    "    reconstructed_image = tf.convert_to_tensor(reconstructed_image)\n",
    "    reconstructed_image = tf.image.yuv_to_rgb(reconstructed_image) * 255\n",
    "\n",
    "    return reconstructed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/keras/engine/training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/keras/engine/training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/keras/engine/training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/keras/engine/training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/keras/engine/training.py\", line 585, in call\n        raise NotImplementedError(\n\n    NotImplementedError: Exception encountered when calling layer 'cvae' (type CVAE).\n    \n    Unimplemented `tf.keras.Model.call()`: if you intend to create a `Model` with the Functional API, please provide `inputs` and `outputs` arguments. Otherwise, subclass `Model` with an overridden `call()` method.\n    \n    Call arguments received by layer 'cvae' (type CVAE):\n      • inputs=tf.Tensor(shape=(None, 8, 8, 3), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m image \u001b[38;5;241m=\u001b[39m image\n\u001b[1;32m      4\u001b[0m image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mrgb_to_yuv(image)\n\u001b[0;32m----> 6\u001b[0m reconstructed_image_32 \u001b[38;5;241m=\u001b[39m \u001b[43mcompress_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m reconstructed_image_32 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(reconstructed_image_32, tf\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# reconstructed_image_32 = reconstructed_image_32 * 255\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 23\u001b[0m, in \u001b[0;36mcompress_image\u001b[0;34m(image, network)\u001b[0m\n\u001b[1;32m     20\u001b[0m image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mextract_patches(image, sizes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, patch_size, patch_size, \u001b[38;5;241m1\u001b[39m], strides\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, patch_size, patch_size, \u001b[38;5;241m1\u001b[39m], rates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m], padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALID\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(image, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, patch_size,patch_size,\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m reconstructed_patches \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m reconstructed_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((height, width, channels))\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(no_patches_height):\n",
      "File \u001b[0;32m~/anaconda3/envs/disertatie/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filexkbnl24a.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/keras/engine/training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/keras/engine/training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/keras/engine/training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/keras/engine/training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/keras/engine/training.py\", line 585, in call\n        raise NotImplementedError(\n\n    NotImplementedError: Exception encountered when calling layer 'cvae' (type CVAE).\n    \n    Unimplemented `tf.keras.Model.call()`: if you intend to create a `Model` with the Functional API, please provide `inputs` and `outputs` arguments. Otherwise, subclass `Model` with an overridden `call()` method.\n    \n    Call arguments received by layer 'cvae' (type CVAE):\n      • inputs=tf.Tensor(shape=(None, 8, 8, 3), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "image = tf.image.decode_image(tf.io.read_file('ciob.png'), channels=3, dtype='float32')\n",
    "\n",
    "image = image\n",
    "image = tf.image.rgb_to_yuv(image)\n",
    "\n",
    "reconstructed_image_32 = compress_image(image, model)\n",
    "reconstructed_image_32 = tf.cast(reconstructed_image_32, tf.uint8)\n",
    "# reconstructed_image_32 = reconstructed_image_32 * 255\n",
    "\n",
    "image = tf.image.yuv_to_rgb(image)\n",
    "image = tf.cast(image * 255, tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax, fig = plt.subplots(1, 2)\n",
    "fig[0].imshow(image)\n",
    "fig[1].imshow(reconstructed_image_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# compute psnr\n",
    "tf.image.psnr(image, reconstructed_image_32, max_val=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "tf.image.ssim(image, reconstructed_image_32, max_val=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "tf.image.ssim_multiscale(image, reconstructed_image_32, max_val=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "encoder = tensorflow.keras.Model(image_input, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "image = tf.image.decode_image(tf.io.read_file('ciob.png'), channels=3, dtype='float32')\n",
    "image = tf.image.rgb_to_yuv(image)\n",
    "\n",
    "image_, _, _ = pad_image(image, PATCH_SIZE)\n",
    "\n",
    "no_patches_width = image_.shape[1] // PATCH_SIZE\n",
    "no_patches_height = image_.shape[0] // PATCH_SIZE\n",
    "\n",
    "width = image_.shape[1]\n",
    "height = image_.shape[0]\n",
    "\n",
    "image_ = tf.expand_dims(image_, axis=0)\n",
    "img_patches = tf.image.extract_patches(image_, sizes=[1, PATCH_SIZE, PATCH_SIZE, 1], strides=[1, PATCH_SIZE, PATCH_SIZE, 1], rates=[1, 1, 1, 1], padding='VALID')\n",
    "img_patches = tf.reshape(img_patches, [-1, PATCH_SIZE, PATCH_SIZE, 3])\n",
    "\n",
    "encoded_patches = encoder.predict(img_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "encoded_patches = encoded_patches.astype(np.float16)\n",
    "copy_encoded_patches = encoded_patches.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# keep only the first 4 decimals\n",
    "encoded_patches = np.around(encoded_patches, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "decoder_input = tensorflow.keras.layers.Input(shape=(1, 1, 8))\n",
    "decoder = tensorflow.keras.Model(encoded, decoded)\n",
    "\n",
    "rec = decoder.predict(encoded_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "reconstructed_image_16 = np.zeros((height, width, 3))\n",
    "\n",
    "for i in range(no_patches_height):\n",
    "    for j in range(no_patches_width):\n",
    "        patch = rec[i*no_patches_width+j].reshape(PATCH_SIZE, PATCH_SIZE, 3)\n",
    "        reconstructed_image_16[i*PATCH_SIZE:(i+1)*PATCH_SIZE, j*PATCH_SIZE:(j+1)*PATCH_SIZE] = patch\n",
    "\n",
    "reconstructed_image_16 = reconstructed_image_16[:image.shape[0], :image.shape[1]]\n",
    "reconstructed_image_16 = tf.convert_to_tensor(reconstructed_image_16)\n",
    "reconstructed_image_16 = tf.image.yuv_to_rgb(reconstructed_image_16) * 255\n",
    "reconstructed_image_16 = tf.cast(reconstructed_image_16, tf.uint8)\n",
    "\n",
    "image = tf.image.yuv_to_rgb(image)\n",
    "image = tf.cast(image * 255, tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax, fig = plt.subplots(1, 2)\n",
    "fig[0].imshow(image)\n",
    "fig[1].imshow(reconstructed_image_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "tf.image.psnr(image, reconstructed_image_16, max_val=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "tf.image.ssim(image, reconstructed_image_16, max_val=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "tf.image.ssim_multiscale(image, reconstructed_image_16, max_val=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/home/cezar/anaconda3/envs/disertatie/lib/python3.11/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "encoded_patches.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disertatie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
